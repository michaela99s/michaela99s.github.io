---
layout: post
title: 투표여부 분석
description: >
  범주형데이터를 다루고, 더 나은 성능의 이진분류를 수행합니다.
  이 포스트는 데이터캠퍼스의 [공개적 빅데이터 분석기사 실기]를 따라 작성되었습니다.
sitemap: false
hide_last_modified: true
---

이진분류분석 문제를 풀어보도록 하겠습니다.

# 투표 데이터셋 분석하기

## 분석 준비

```python
import pandas as pd

df = pd.read_csv('vote.csv')
df.head()
```

|     | gender | region | edu | income | age | score_gov | score_progress | score_intention | vote | parties |
| --- | ------ | ------ | --- | ------ | --- | --------- | -------------- | --------------- | ---- | ------- |
| 0   | 1      | 4      | 3   | 3      | 3   | 2         | 2              | 4.0             | 1    | 2       |
| 1   | 1      | 5      | 2   | 3      | 3   | 2         | 4              | 3.0             | 0    | 3       |
| 2   | 1      | 3      | 1   | 2      | 4   | 1         | 3              | 2.8             | 1    | 4       |
| 3   | 2      | 1      | 2   | 1      | 3   | 5         | 4              | 2.6             | 1    | 1       |
| 4   | 1      | 1      | 1   | 2      | 4   | 4         | 3              | 2.4             | 1    | 1       |

이 데이터셋의 레이블(y)은 두 개입니다. 첫번째 vote는 투표여부를 나타냅니다. vote의 값이 1이면 투표를 했음을 나타냅니다. 다른 레이블은 parties로 지지정당을 나타내며, [1, 2, 3, 4]의 값을 갖습니다. 

피쳐변수들에도 범주형 변수들이 포함되어 있습니다.  성별을 나타내는 gender와 지역을 나타내는 region이 이에 해당합니다. gender 변수의 범주는 두 가지이며, region 변수의 범주는 5가지로 나뉘어집니다. 

### One-Hot-Encoding

범주형 변수가 있을 때, 범주를 나타내는 값이 크기를 나타낸다고 인식될 가능성이 있습니다. 이를 방지하기 위하여 원-핫 인코딩을 진행합니다. 원-핫 인코딩 결과 범주 수만큼 변수들이 생성되며 각 변수들에는 0 또는 1의 값이 배정됩니다. 

vote 데이터셋의 gender와 region 변수에 대하여 원-핫 인코딩을 수행하도록 하겠습니다. 먼저 범주형 변수들을 따로 분리하도록 합니다.

```python
df_cat = df[['gender', 'region']]
df_ = df.drop(['gender', 'region'], axis=1)
```

변수 변환에 앞서 각 변수에 할당되어 있는 수치들을 문자로 변환하도록 하겠습니다. 
gender의 경우, 1을 male, 2를 female로 변경하겠습니다.
region은 1을 Sudo, 2를 Chungcheung, 3을 Honam, 4를 Youngnam, 5를 Others로 바꾸도록 하겠습니다. 

```python
df_cat['gender'] = df_cat['gender'].replace([1, 2], ['male', 'female'])
df_cat['region'] = df_cat['region'].replace([1, 2, 3, 4, 5],
                                            ['Sudo', 'Chungcheung', 'Honam',
                                             'Youngnam', 'Others'])
df_cat.head()
```

|     | gender | region   |
| --- | ------ | -------- |
| 0   | male   | Youngnam |
| 1   | male   | Others   |
| 2   | male   | Honam    |
| 3   | female | Sudo     |
| 4   | male   | Sudo     |

판다스의 `get_dummies`를 이용하여 변수변환을 시도해보겠습니다. 

```python
pandas.get_dummies(data, prefix=None, prefix_sep='_', dummy_na=False, 
columns=None, sparse=False, drop_first=False, dtype=None)
```

```python
df_dum = pd.get_dummies(df_cat)
df_dum.head()
```

|     | gender_female | gender_male | region_Chungcheung | region_Honam | region_Others | region_Sudo | region_Youngnam |
| --- | ------------- | ----------- | ------------------ | ------------ | ------------- | ----------- | --------------- |
| 0   | 0             | 1           | 0                  | 0            | 0             | 0           | 1               |
| 1   | 0             | 1           | 0                  | 0            | 1             | 0           | 0               |
| 2   | 0             | 1           | 0                  | 1            | 0             | 0           | 0               |
| 3   | 1             | 0           | 0                  | 0            | 0             | 1           | 0               |
| 4   | 0             | 1           | 0                  | 0            | 0             | 1           | 0               |

원-핫 인코딩 결과 총 7개의 컬럼이 생성됩니다. 

이제 원-핫인코딩한 결과를 나머지 데이터셋에 다시 합쳐주도록 합니다. 나중에 다시 사용할 때를 대비하여 새로운 csv파일로 저장도 해줍니다.

```python
df1 = pd.concat([df_dum, df_], axis=1)
df1.to_csv("Fvote.csv")
df1.head()
```

|     | gender_female | gender_male | region_Chungcheung | region_Honam | region_Others | region_Sudo | region_Youngnam | edu | income | age | score_gov | score_progress | score_intention | vote | parties |
| --- | ------------- | ----------- | ------------------ | ------------ | ------------- | ----------- | --------------- | --- | ------ | --- | --------- | -------------- | --------------- | ---- | ------- |
| 0   | 0             | 1           | 0                  | 0            | 0             | 0           | 1               | 3   | 3      | 3   | 2         | 2              | 4.0             | 1    | 2       |
| 1   | 0             | 1           | 0                  | 0            | 1             | 0           | 0               | 2   | 3      | 3   | 2         | 4              | 3.0             | 0    | 3       |
| 2   | 0             | 1           | 0                  | 1            | 0             | 0           | 0               | 1   | 2      | 4   | 1         | 3              | 2.8             | 1    | 4       |
| 3   | 1             | 0           | 0                  | 0            | 0             | 1           | 0               | 2   | 1      | 3   | 5         | 4              | 2.6             | 1    | 1       |
| 4   | 0             | 1           | 0                  | 0            | 0             | 1           | 0               | 1   | 2      | 4   | 4         | 3              | 2.4             | 1    | 1       |

### 피쳐와 레이블 분리

본격적인 분석을 위하여 피쳐변수들과 레이블 변수로 데이터셋을 나누어주도록 합니다. 우선 vote를 레이블 변수로 하겠습니다.

```python
X = df1.drop(['vote', 'parties'], axis=1)
y = df1.vote
```

데이터의 균형 여부를 파악하기 위하여 `value_counts()`를 사용해봅니다.

```python
y.value_counts()
```

```
1    150
0     61
Name: vote, dtype: int64
```

1의 빈도가 0의 빈도의 2.5배 가량을 기록하고 있으므로 데이터의 불균형이 감지됩니다. 따라서 훈련데이터와 테스트데이터를 나눌 때, 레이블 비율에 유의해야합니다.

### 트레인-테스트 데이터셋 나누기

```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)
```

데이터 불균형이 의심되므로 데이터셋을 나눌 때, stratify=y를 설정해줍니다. 

## 모델 학습

분류분석이므로 분류 모델 중 로지스틱 회귀를 사용하겠습니다. 

```python
from sklearn.linear_model import LogisticRegression

model = LogisticRegression()
```

이전과는 달리 이제는 검증셋(Validation Set)의 개념을 도입하겠습니다. 
검증셋은 훈련데이터의 일부로, 훈련하는 동안 모델의 성능을 검증하는 역할을 합니다. 이러한 검증 과정은 하이퍼파라미터 튜닝에 있어서 특히 의미를 가집니다. 검증셋에서의 결과를 바탕으로 모델을 선택하고 마지막으로 테스트셋에서 최종 모델의 성능을 확인하는 과정을 거치게 됩니다. 또한 검증셋의 결과를 바탕으로 오버피팅을 방지할 수도 있습니다.  

그러나 데이터셋이 크지 않은 경우 트레인셋에서 검증셋을 따로 나누기에는 부담이 있습니다. 이러한 한계를 극복하기 위하여 교차검증(Cross Validation)을 활용합니다.

### 교차검증

교차검증에서는 트레인셋을 여러 그룹으로 나누어 번갈아 가면서 검증셋으로 역할하게 합니다. 따라서 만약 5개의 그룹으로 나누었을 경우, 먼저 1그룹을 검증셋으로 하고 나머지 4개 그룹을 훈련셋으로 하여 검증셋에서의 성능을 확인합니다. 그 다음 2그룹을 검증셋으로 하고 나머지 4개를 훈련셋으로 하여 2그룹의 성능을 확인합니다. 이런 식으로 총 5번의 학습이 진행됩니다. 

교차검증 방법으로는 사이킷런의 model_selection에 있는 `cross_val_score`가 있습니다. 

```python
sklearn.model_selection.cross_val_score(estimator, X, y=None, *, 
groups=None, scoring=None, cv=None, n_jobs=None, verbose=0, 
fit_params=None, pre_dispatch='2*n_jobs', error_score=nan)
```

훈련데이터를 5그룹으로 나누는 교차검증을 수행합니다.

```python
from sklearn.model_selection import cross_val_score

scores = cross_val_score(model, X_train, y_train, cv=5)
print(f"5개 검증세트의 정확도: {scores}")
print(f"정확도 평균: {scores.mean():.4f}")
```
```
5개 검증세트의 정확도: [0.71875    0.6875     0.8125     0.58064516 0.80645161]
정확도 평균: 0.7212
```

#### 랜덤한 교차검증: K-fold

`cross_val_score`는 데이터셋을 순서대로 분할합니다. 따라서 데이터가 저장된 순서가 중요해집니다. 특히, 데이터 순서에 편향이 있다면 모델의 성능을 보장하기 어렵습니다. 이러한 점을 보완하기 위하여. 사이킷런 model_selection의 KFold를 이용하여 훈련데이터의 순서를 랜덤하게 섞어서 그룹으로 나누도록 합니다. 

```python
sklearn.model_selection.KFold(n_splits=5, *, shuffle=False, 
random_state=None)
```

랜덤하게 섞기 위하여 shuffle=True로 설정하도록 합니다. 

```python
from sklearn.model_selection import KFold

kfold = KFold(n_splits=5, shuffle=True, random_state=42)
score = cross_val_score(model, X_train, y_train, cv=kfold)
print(f"5개 폴드의 정확도: {score}")
```
```
5개 폴드의 정확도: [0.71875    0.6875     0.625      0.70967742 0.77419355]
```
#### 임의분할 교차검증

앞선 교차검증방법들과 달리, 임의분할 교차검증은 다른 폴드에서 사용되었던 데이터도 랜덤하게 데이터를 구성하게 하는 방법입니다. 따라서 전체 데이터 중 일부는 훈련데이터와 검증데이터에서 단 한 번도 사용되지 않을 수 있습니다. 

```python
sklearn.model_selection.ShuffleSplit(n_splits=10, *, test_size=None, 
train_size=None, random_state=None)
```

K-Fold에서와 마찬가지로 shuffle_split을 통해서 데이터를 나누고 `cross_val_score`의 cv에 지정해주도록 합니다.

```python
from sklearn.model_selection import ShuffleSplit

shuffle_split = ShuffleSplit(test_size=.5, random_state=42)
score = cross_val_score(model, X_train, y_train, cv=shuffle_split)
print(f"교차검증 정확도: {score}")
```

```
교차검증 정확도: [0.73417722 0.69620253 0.70886076 0.73417722 0.65822785 0.67088608
 0.72151899 0.65822785 0.69620253 0.70886076]
```

### train-validation-test 분할

데이터 수가 충분히 확보된 경우에는 교차검증을 하지 않고 train-validation-test set을 분할할 수 있습니다. `train_test_split`을 두 번 실행하면 train-validation-test 분할이 가능합니다. 첫 번째 실행에서는 테스트셋을 분리해내고 두 번째 실행에서는 train-validaion set을 분리해냅니다. 

```python
X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, random_state=1)
X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, 
                                                  random_state=2)
```

### 모델 훈련

```python
model.fit(X_train, y_train)

print(f"train set의 정확도: {model.score(X_train, y_train):.4f}")
print(f"validation set의 정확도: {model.score(X_val, y_val):.4f}")
print(f"test set의 정확도: {model.score(X_test, y_test):.4f}")
```
```
train set의 정확도: 0.7288
validation set의 정확도: 0.6500
test set의 정확도: 0.6981
```

### 하이퍼파라미터 튜닝

데이터 분석 알고리즘에는 하이퍼파라미터(hyperparameter)가 있습니다. 하이퍼파라미터란, 학습과정에서 결정되는 것이 아닌, 분석자가 결정하는 변수입니다. 하이퍼파라미터를 어떻게 설정하느냐에 따라 모델의 성능이 변하게 됩니다. 따라서 적절한 하이퍼파라미터를 찾는다면 모델의 성능을 개선할 수 있습니다. 이처럼 최적의 하이퍼파라미터를 찾는 과정을 하이퍼파라미터 튜닝이라고 합니다. 하이퍼파라미터 튜닝 방법에는 그리드 서치(Grid Search)와 랜덤 서치(Random Search)가 있습니다.

#### Grid Search

그리드 서치는 주어진 하이퍼파라미터 값들을 모두 사용하여 최적의 결과를 찾아냅니다. 사이킷런의 model_selection에 `GridSearchCV`를 이용하여 그리드 서치를 진행합니다. 모델의 평가는 교차검증 방식으로 수행됩니다.

```python
sklearn.model_selection.GridSearchCV(estimator, param_grid, *, 
scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, 
pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)
```



로지스틱 회귀에는 규제 정도를 나타내는 C라는 하이퍼파라미터가 있습니다. 기본값은 1이며 이 값이 커질수록 규제 정도는 작아집니다. 자세한 내용은 뒤에서 다루겠습니다. 
여기에서는 C값의 범위를 [0.001, 0.01, 0.1, 1, 10, 100]으로 두어 최적의 C를 찾도록 하겠습니다. 

```python
from sklearn.model_selection import GridSearchCV

param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}

grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, return_train_score=True)
grid_search.fit(X_train, y_train)

print(f"Best Parameter: {grid_search.best_params_}")
print(f"Best Cross-Validation Score: {grid_search.best_score_:.3f}")
print(f"Test Score: {grid_search.score(X_test, y_test):.3f}")
```
```
Best Parameter: {'C': 10}
Best Cross-Validation Score: 0.727
Test Score: 0.679
```

C가 10일 때, 즉 규제가 다소 약할 때, 최적의 모델을 구할 수 있으며 이 때의 정확도는 67.9%입니다. 보다 자세한 결과값을 살펴보기 위해서는 `cv_results_`메소드를 사용합니다.

```python
result_grid = pd.DataFrame(grid_search.cv_results_)
result_grid
```

|     | mean_fit_time | std_fit_time | mean_score_time | std_score_time | param_C | params       | split0_test_score | split1_test_score | split2_test_score | split3_test_score | ... | mean_test_score | std_test_score | rank_test_score | split0_train_score | split1_train_score | split2_train_score | split3_train_score | split4_train_score | mean_train_score | std_train_score |
| --- | ------------- | ------------ | --------------- | -------------- | ------- | ------------ | ----------------- | ----------------- | ----------------- | ----------------- | --- | --------------- | -------------- | --------------- | ------------------ | ------------------ | ------------------ | ------------------ | ------------------ | ---------------- | --------------- |
| 0   | 0.004023      | 0.000877     | 0.001043        | 0.000663       | 0.001   | {'C': 0.001} | 0.68750           | 0.71875           | 0.71875           | 0.709677          | ... | 0.708871        | 0.011430       | 5               | 0.714286           | 0.706349           | 0.706349           | 0.708661           | 0.708661           | 0.708861         | 0.002903        |
| 1   | 0.003384      | 0.000504     | 0.000633        | 0.000454       | 0.01    | {'C': 0.01}  | 0.68750           | 0.71875           | 0.71875           | 0.709677          | ... | 0.708871        | 0.011430       | 5               | 0.714286           | 0.706349           | 0.706349           | 0.708661           | 0.708661           | 0.708861         | 0.002903        |
| 2   | 0.005085      | 0.000629     | 0.000998        | 0.000006       | 0.1     | {'C': 0.1}   | 0.71875           | 0.71875           | 0.71875           | 0.677419          | ... | 0.721573        | 0.030797       | 3               | 0.730159           | 0.738095           | 0.738095           | 0.740157           | 0.708661           | 0.731034         | 0.011698        |
| 3   | 0.006228      | 0.000396     | 0.001005        | 0.000018       | 1       | {'C': 1}     | 0.71875           | 0.68750           | 0.81250           | 0.580645          | ... | 0.721169        | 0.085441       | 4               | 0.738095           | 0.785714           | 0.730159           | 0.763780           | 0.724409           | 0.748431         | 0.022993        |
| 4   | 0.009993      | 0.001795     | 0.000801        | 0.000400       | 10      | {'C': 10}    | 0.75000           | 0.68750           | 0.81250           | 0.580645          | ... | 0.727419        | 0.086175       | 1               | 0.746032           | 0.769841           | 0.730159           | 0.779528           | 0.724409           | 0.749994         | 0.021586        |
| 5   | 0.011014      | 0.001433     | 0.000600        | 0.000801       | 100     | {'C': 100}   | 0.75000           | 0.68750           | 0.81250           | 0.580645          | ... | 0.727419        | 0.086175       | 1               | 0.746032           | 0.769841           | 0.730159           | 0.771654           | 0.724409           | 0.748419         | 0.019567        |

6 rows × 21 columns

하이퍼파라미터 C값에 따른 모델 성능을 시각화해볼 수도 있습니다.

import matplotlib.pyplot as plt

```python
plt.plot(result_grid['param_C'], result_grid['mean_train_score'], label="Train")
plt.plot(result_grid['param_C'], result_grid['mean_test_score'], label="Test")
plt.legend()
```

![](data:image/png;base64,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)

#### Random Search

그리드서치의 단점은 하이퍼파라미터의 수가 많아질 수록 계산 시간이 길어져 비효율적이라는 것입니다. 따라서 이를 보완하기 위해 랜덤 서치가 사용됩니다. 랜덤 서치 역시 사이킷런의 model_selection에 있는 `RandomizedSearchCV`를 사용하게 됩니다. 

```python
sklearn.model_selection.RandomizedSearchCV(estimator, 
param_distributions, *, n_iter=10, scoring=None, n_jobs=None, 
refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', 
random_state=None, error_score=nan, return_train_score=False)
```

랜덤 서치는 그리드 서치와 달리 모든 조합을 시도하기보다는 랜덤으로 하이퍼파라미터에 값을 대입합니다. n_iter는 추출될 파라미터 수를 의미합니다. 이 값이 커질수록 분석의 질은 높아지겠지만 소요시간이 길어집니다. 

이번에는 하이퍼파라미터 C를 0.001과 100 사이의 범위에서 무작위로 추출하도록 합니다.

```python
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint

param_distribs = {'C': randint(low=0.001, high=100)}

random_search = RandomizedSearchCV(LogisticRegression(max_iter=1000), 
                                   param_distributions=param_distribs, 
                                   cv=5, return_train_score=True)
random_search.fit(X_train, y_train)

print(f"Best Parameter: {random_search.best_params_}")
print(f"Best Cross-Validation Score: {random_search.best_score_:.3f}")
print(f"Test Score: {random_search.score(X_test, y_test):.3f}")
```
```
Best Parameter: {'C': 48}
Best Cross-Validation Score: 0.727
Test Score: 0.679
```

최적 하이퍼파라미터 값은 달라도 모델의 성능은 그리드서치와 유사하게 나타남을 알 수 있습니다. 

```python
result_random = random_search.cv_results_
pd.DataFrame(result_random)
```

|     | mean_fit_time | std_fit_time | mean_score_time | std_score_time | param_C | params    | split0_test_score | split1_test_score | split2_test_score | split3_test_score | ... | mean_test_score | std_test_score | rank_test_score | split0_train_score | split1_train_score | split2_train_score | split3_train_score | split4_train_score | mean_train_score | std_train_score |
| --- | ------------- | ------------ | --------------- | -------------- | ------- | --------- | ----------------- | ----------------- | ----------------- | ----------------- | --- | --------------- | -------------- | --------------- | ------------------ | ------------------ | ------------------ | ------------------ | ------------------ | ---------------- | --------------- |
| 0   | 0.055738      | 0.090584     | 0.000786        | 0.000394       | 94      | {'C': 94} | 0.75              | 0.6875            | 0.8125            | 0.580645          | ... | 0.727419        | 0.086175       | 1               | 0.746032           | 0.769841           | 0.730159           | 0.771654           | 0.724409           | 0.748419         | 0.019567        |
| 1   | 0.009792      | 0.001161     | 0.000652        | 0.000542       | 10      | {'C': 10} | 0.75              | 0.6875            | 0.8125            | 0.580645          | ... | 0.727419        | 0.086175       | 1               | 0.746032           | 0.769841           | 0.730159           | 0.779528           | 0.724409           | 0.749994         | 0.021586        |
| 2   | 0.010482      | 0.000526     | 0.000597        | 0.000487       | 67      | {'C': 67} | 0.75              | 0.6875            | 0.8125            | 0.580645          | ... | 0.727419        | 0.086175       | 1               | 0.746032           | 0.769841           | 0.730159           | 0.771654           | 0.724409           | 0.748419         | 0.019567        |
| 3   | 0.010091      | 0.000654     | 0.000799        | 0.000399       | 70      | {'C': 70} | 0.75              | 0.6875            | 0.8125            | 0.580645          | ... | 0.727419        | 0.086175       | 1               | 0.746032           | 0.769841           | 0.730159           | 0.771654           | 0.724409           | 0.748419         | 0.019567        |
| 4   | 0.008872      | 0.001085     | 0.001018        | 0.000033       | 4       | {'C': 4}  | 0.75              | 0.6875            | 0.8125            | 0.580645          | ... | 0.727419        | 0.086175       | 1               | 0.746032           | 0.777778           | 0.730159           | 0.779528           | 0.724409           | 0.751581         | 0.023218        |
| 5   | 0.009843      | 0.001291     | 0.000624        | 0.000486       | 9       | {'C': 9}  | 0.75              | 0.6875            | 0.8125            | 0.580645          | ... | 0.727419        | 0.086175       | 1               | 0.746032           | 0.769841           | 0.730159           | 0.779528           | 0.724409           | 0.749994         | 0.021586        |
| 6   | 0.008479      | 0.001147     | 0.000831        | 0.000419       | 5       | {'C': 5}  | 0.75              | 0.6875            | 0.8125            | 0.580645          | ... | 0.727419        | 0.086175       | 1               | 0.746032           | 0.777778           | 0.730159           | 0.779528           | 0.724409           | 0.751581         | 0.023218        |
| 7   | 0.010193      | 0.000746     | 0.001011        | 0.000032       | 69      | {'C': 69} | 0.75              | 0.6875            | 0.8125            | 0.580645          | ... | 0.727419        | 0.086175       | 1               | 0.746032           | 0.769841           | 0.730159           | 0.771654           | 0.724409           | 0.748419         | 0.019567        |
| 8   | 0.009839      | 0.001145     | 0.000804        | 0.000402       | 72      | {'C': 72} | 0.75              | 0.6875            | 0.8125            | 0.580645          | ... | 0.727419        | 0.086175       | 1               | 0.746032           | 0.769841           | 0.730159           | 0.771654           | 0.724409           | 0.748419         | 0.019567        |
| 9   | 0.010514      | 0.001041     | 0.000789        | 0.000395       | 75      | {'C': 75} | 0.75              | 0.6875            | 0.8125            | 0.580645          | ... | 0.727419        | 0.086175       | 1               | 0.746032           | 0.769841           | 0.730159           | 0.771654           | 0.724409           | 0.748419         | 0.019567        |

10 rows × 21 columns
