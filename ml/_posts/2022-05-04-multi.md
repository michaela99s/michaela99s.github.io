---
layout: post
title: 지지정당 분석
description: >
  더 나은 성능의 다중분류를 수행합니다.
  이 포스트는 데이터캠퍼스의 [공개적 빅데이터 분석기사 실기]를 따라 작성되었습니다.
sitemap: false
hide_last_modified: true
---

투표 데이터셋에서 또 다른 레이블인 정당을 나타내는 parties에 대한 분류 분석을 진행해보겠습니다. parties에는 4개의 값이 있으므로 다중분류가 됩니다.

## 분석준비

이전에 원-핫 인코딩 후 저장해두었던 데이터셋을 불러와 피쳐들과 레이블로 나눕니다.

```python
import pandas as pd

df = pd.read_csv('Fvote.csv')

X = df.drop(['vote', 'parties'], axis=1)
y = df.parties
```

y값의 빈도 수를 보면 네 정당에 골고루 분포가 되어 있지 않다는 것을 알 수 있습니다.

```python
y.value_counts().sort_index()
```
```
1    50
2    53
3    25
4    83
Name: parties, dtype: int64
```

### train-test split

레이블값의 불균형이 있으므로 레이블을 기준으로 층화되도록 데이터를 분할합니다. 

```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, 
                                                    random_state=42)
```

## 모델 학습

로지스틱 회귀를 이용하여 분류분석을 합니다.

```python
from sklearn.linear_model import LogisticRegression

model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)

pred_train = model.predict(X_train)
print(f"트레인셋 정확도: {model.score(X_train, y_train):.4f}")

pred_test = model.predict(X_test)
print(f"테스트셋 정확도: {model.score(X_test, y_test):.4f}")
```
```
트레인셋 정확도: 0.6013
테스트셋 정확도: 0.5472
```

트레인셋과 테스트셋에서 모두 정확도가 충분히 높지 않다고 느껴집니다. 

혼동행렬을 살펴보도록 하겠습니다.

```python
from sklearn.metrics import confusion_matrix

confusion_train = confusion_matrix(y_train, pred_train)
print("훈련데이터 오차행렬: \n", confusion_train)
print("")
confusion_test = confusion_matrix(y_test, pred_test)
print("테스트데이터 오차행렬: \n", confusion_test)
```

```
훈련데이터 오차행렬: 
 [[19  2  3 13]
 [ 1 25  2 12]
 [ 6  2  5  6]
 [ 7  8  1 46]]

테스트데이터 오차행렬: 
 [[ 7  2  1  3]
 [ 1  9  1  2]
 [ 1  2  1  2]
 [ 2  5  2 12]]
```

정당 3의 정분류 수가 가장 낮게 나타나고 있습니다. 

모델의 성능을 개선하기 위하여 하이퍼파라미터 튜닝을 시도해보겠습니다.

### 하이퍼파라미터 튜닝

#### 그리드서치

```python
from sklearn.model_selection import GridSearchCV

param_grid = {'C': [.001, .01, .1, 1, 10, 100]}
grid_search = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5, 
                           return_train_score=True)
grid_search.fit(X_train, y_train)

print(f"Best Parameter: {grid_search.best_params_}")
print(f"Best Cross-Validation Score: {grid_search.best_score_:.3f}")
print(f"Test Score: {grid_search.score(X_test, y_test):.3f}")
```
```
Best Parameter: {'C': 0.1}
Best Cross-Validation Score: 0.556
Test Score: 0.547
```

#### 랜덤서치

```python
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint

param_distribs = {'C': randint(low=0.001, high=100)}

random_search = RandomizedSearchCV(LogisticRegression(max_iter=1000),
                                   param_distributions=param_distribs, cv=5,
                                   return_train_score=True)
random_search.fit(X_train, y_train)

print(f"Best Parameter: {random_search.best_params_}")
print(f"Best Cross-Validation Score: {random_search.best_score_: .3f}")
print(f"Test Score: {random_search.score(X_test, y_test):.3f}")
```
```
Best Parameter: {'C': 2}
Best Cross-Validation Score:  0.544
Test Score: 0.509
```

하이퍼파라미터 튜닝 이후에도 모델의 성능은 크게 개선되지 않았으며 랜덤서치의 경우 성능이 오히려 나빠지게 되었습니다. 이는 선택된 알고리즘이 적절하지 않았거나 선정된 피쳐들로 분류 분석을 하기에는 어려움이 있음을 암시합니다.